{
  "marketingName": "Seedance 2.0",
  "versionLabel": "2.0",
  "seo": {
    "title": "Seedance 2.0 (ByteDance) — AI Video with Native Audio & Multi-Shot Control | MaxVideoAI",
    "description": "Explore ByteDance Seedance 2.0 before launch: native audio generation, 1080p up to 15s, multi-shot outputs, cinematic camera language, and structured prompt templates. Launch expected Feb 24, 2026."
  },
  "overview": "Seedance 2.0 is ByteDance's next-gen AI video model focused on cinematic motion, multi-shot continuity, and native audio generated in sync with visuals. This page is a pre-launch overview: specs, best use cases, and prompt templates so you can plan workflows before release.",
  "pricingNotes": "Pre-launch: pricing and commercial terms are confirmed at launch.",
  "hero": {
    "title": "Seedance 2.0",
    "intro": "Seedance 2.0 is ByteDance's next-gen AI video model focused on cinematic motion, multi-shot continuity, and native audio generated in sync with visuals. This page is a pre-launch overview: specs, best use cases, and prompt templates so you can plan workflows before release.",
    "badge": "Coming soon · Expected launch: February 24, 2026",
    "ctaPrimary": {
      "label": "Join waitlist / Get notified",
      "href": "https://fal.ai/seedance-2-0"
    },
    "secondaryLinks": [
      {
        "label": "See Seedance 1.5 Pro",
        "href": "/models/seedance-1-5-pro"
      },
      {
        "label": "Read official launch details",
        "href": "https://seed.bytedance.com/en/blog/official-launch-of-seedance-2-0"
      }
    ]
  },
  "bestUseCases": {
    "title": "Use cases",
    "items": [
      {
        "title": "Action sequences with more believable physics and interaction",
        "icon": "camera"
      },
      {
        "title": "Multi-shot ads with consistent product and scene continuity",
        "icon": "product"
      },
      {
        "title": "Music-led visuals with synced ambience and SFX cues",
        "icon": "music"
      },
      {
        "title": "Storyboard-to-video using text and multimodal references",
        "icon": "storyboard"
      },
      {
        "title": "Director-style camera moves, transitions, and framing control",
        "icon": "clapperboard"
      },
      {
        "title": "Pre-visualization before final edit (concept to shot list to rough cut)",
        "icon": "layers"
      }
    ]
  },
  "technicalOverviewTitle": "Technical overview",
  "technicalOverview": [
    {
      "label": "Launch status",
      "body": "Coming soon. Expected launch: February 24, 2026. Available on fal.ai February 24, 2026. Pre-launch page is indexable; runtime generation remains locked before launch."
    },
    {
      "label": "Inputs",
      "body": "Text + image + audio + video references"
    },
    {
      "label": "Reference limits",
      "body": "Up to 9 images, 3 video clips, and 3 audio clips, plus text instructions"
    },
    {
      "label": "Duration",
      "body": "Up to 15s per generation with multi-shot continuity in one output"
    },
    {
      "label": "Audio",
      "body": "Official materials highlight native audio generated alongside video, including audio-video sync"
    },
    {
      "label": "Camera and motion",
      "body": "Advanced camera and motion controls, with best results from explicit shot direction"
    },
    {
      "label": "Notes",
      "body": "ByteDance describes extension/editing capabilities; final endpoint exposure on fal.ai depends on launch endpoints."
    }
  ],
  "promptStructure": {
    "title": "Prompting Seedance 2.0",
    "quote": "[Genre] + [subject] + [setting] + [action beats] + [camera language] + [audio cues] + [duration <=15s] + [shot structure].",
    "description": "For best consistency, keep each beat explicit and define camera transitions and audio timing in the same prompt.",
    "steps": [
      "Define genre and core subject",
      "Set location and visual anchors",
      "Write 2-4 shot beats with timing",
      "Specify camera motion and transitions",
      "Add dialogue, ambience, and SFX cues"
    ]
  },
  "promptingTip": "Tip: Seedance 2.0 rewards shot timing, camera verbs, and audio cues. Keep dialogue short, pin SFX to visible actions, and use references to lock continuity.",
  "tips": {
    "title": "Limitations and pre-launch notes",
    "items": [
      "Model page is live and indexable before launch; generation is locked until February 24, 2026.",
      "Commercial usage details are confirmed at launch via fal.ai terms.",
      "Advanced editing and extension capabilities depend on launch endpoint exposure.",
      "Keep prompts structured for multi-shot coherence in <=15s outputs."
    ]
  },
  "prompts": [
    {
      "title": "Action chase (multi-shot)",
      "prompt": "Three-shot rooftop chase at dusk, shot 1 wide tracking run, shot 2 handheld close pursuit, shot 3 crane reveal over skyline, realistic footstep impacts and city sirens, 15 seconds total."
    },
    {
      "title": "Continuous spy thriller",
      "prompt": "A spy exits a neon train station, camera follows over shoulder into a rainy alley, rack focus to a coded message, low synth score and distant PA announcements, 12 seconds."
    },
    {
      "title": "3-shot commercial",
      "prompt": "Shot 1 macro of watch crown with rim light, shot 2 wrist hero turntable in studio haze, shot 3 lifestyle close-up in city night rain, punchy transitions and polished ad soundtrack, 15 seconds."
    },
    {
      "title": "Multimodal storyboard reference",
      "prompt": "Use @Image1..@Image9 as storyboard style anchors, @Video1..@Video3 for pacing references, @Audio1..@Audio3 for rhythm and ambience, keep wardrobe continuity and cinematic 16:9 framing."
    },
    {
      "title": "Audio-forward dialogue scene",
      "prompt": "Two-character dialogue in a subway platform at night, synchronized dialogue, ambience and metallic train brakes on cue, smooth dolly and cut-in close-up, stereo mix feel, 10 seconds."
    }
  ],
  "faqTitle": "FAQ – Seedance 2.0 on MaxVideoAI",
  "faqs": [
    {
      "q": "What is Seedance 2.0?",
      "a": "Seedance 2.0 is ByteDance's AI video model focused on cinematic motion, multi-shot continuity, and native audio generation."
    },
    {
      "q": "How long can outputs be?",
      "a": "Launch materials highlight outputs up to 15 seconds per generation."
    },
    {
      "q": "Does it support audio?",
      "a": "Yes. Native audio is highlighted in official messaging, with audio generated alongside video for better sync."
    },
    {
      "q": "When will it be available on MaxVideoAI?",
      "a": "This page is pre-launch. Availability and pricing will be confirmed at launch (currently expected Feb 24, 2026)."
    },
    {
      "q": "Can I generate before launch?",
      "a": "No. The model page can be indexed for discovery, but runtime remains locked until release."
    }
  ],
  "custom": {
    "whyTitle": "What makes Seedance 2.0 different",
    "heroTrustLine": "Pay-as-you-go on MaxVideoAI · Price shown before you generate (at launch)",
    "heroHighlights": [
      "Director-level camera language||Optimized for explicit shot direction: camera movement, framing, and transition verbs",
      "Multi-shot continuity in a single render||Designed for short timelines where multiple beats can be stitched into one coherent output",
      "Native audio generation (visual and sound together)||Official materials highlight audio generated alongside video for stronger sync",
      "Multimodal references at scale||Mix text with image, video, and audio references to lock style, pacing, and continuity"
    ],
    "specTitle": "Specs (pre-launch)",
    "specNote": "Only officially sourced claims are listed here. Availability and final pricing are confirmed at launch.",
    "specSections": [
      {
        "title": "Multimodal input stack",
        "intro": "Seedance 2.0 accepts text, image, audio, and video references.",
        "items": [
          "Text instructions + multimodal references",
          "Up to 9 image references",
          "Up to 3 video references",
          "Up to 3 audio references"
        ]
      },
      {
        "title": "Output style and structure",
        "intro": "Model messaging emphasizes cinematic control and multi-shot outputs.",
        "items": [
          "Up to 1080p",
          "Up to 15s per generation",
          "24 FPS (as announced)",
          "Natural transitions across multiple shots",
          "Native audio-video joint generation",
          "Audio-video sync mentioned in official materials",
          "Dual-channel (stereo) audio support highlighted by ByteDance"
        ]
      }
    ],
    "promptingTitle": "Prompt Lab — Seedance 2.0",
    "promptingGuideLabel": "Official Seedance 2.0 page",
    "promptingGuideUrl": "https://seed.bytedance.com/en/seedance2_0",
    "promptingIntro": "Seedance 2.0 tends to reward shot timing, camera verbs, and audio cues. Keep dialogue short, pin SFX to visible actions, and use references to lock continuity.",
    "promptingGlobalPrinciples": [
      "Use explicit shot timing (0-5s, 5-10s, 10-15s).",
      "Write camera movement and transition verbs clearly.",
      "Keep one clear action beat per shot.",
      "Pin dialogue and SFX to visible moments."
    ],
    "promptingEngineWhy": [
      "The model is optimized for cinematic camera language and controlled motion.",
      "Multi-shot generation benefits from explicit beat structure.",
      "Joint audio-video generation improves sync when audio cues are concise.",
      "Reference-heavy workflows improve consistency across shots."
    ],
    "promptingTabNotes": {
      "quick": "Quick = iterate concept and mood.",
      "structured": "Structured = lock continuity and camera direction.",
      "pro": "Pro = detailed multi-shot direction with sound design.",
      "storyboard": "Storyboard = timeline-driven beats with references."
    },
    "promptingTabs": [
      {
        "id": "quick",
        "label": "Quick",
        "title": "Quick concept prompt",
        "description": "Fast ideation with one cinematic beat.",
        "copy": "[Subject] in [setting]. Camera: [move + lens feel]. Lighting: [style]. Action: [one clear beat]. Audio: [ambience + one SFX cue]. (<=15s, choose aspect ratio in UI.)\n\nExample: Handheld UGC unboxing at a kitchen table. Slow push-in, natural daylight. She peels the seal, smiles, turns the bottle to camera. Room tone + packaging crinkle + soft click when cap opens."
      },
      {
        "id": "structured",
        "label": "Structured",
        "title": "Structured production prompt",
        "description": "Use this to keep consistency in multi-shot outputs.",
        "copy": "Continuity anchors: wardrobe, props, location, time of day\nShot timeline: 0-5s / 5-10s / 10-15s\nFor each shot: subject action + camera move + transition verb\nAudio plan: ambience bed + timed SFX + short dialogue (optional)\nExclusions: avoid / do not include / safety boundaries"
      },
      {
        "id": "pro",
        "label": "Pro",
        "title": "Director brief prompt",
        "description": "Detailed cinematic control with synchronized sound design.",
        "copy": "Director intent (1 sentence):\nVisual anchors:\nShot timeline + transitions:\nCamera language: push-in / whip pan / crane / handheld / locked-off\nSound design: ambience, SFX hits, dialogue length\nConstraints + negatives: no text overlays, no logos, no shaky cam, etc."
      },
      {
        "id": "storyboard",
        "label": "Storyboard",
        "title": "Storyboard multimodal prompt",
        "description": "Reference-driven prompting with images, videos, and audio.",
        "copy": "Use @Image1..@Image9 to lock style and characters.\nUse @Video1..@Video3 for pacing and camera rhythm.\nUse @Audio1..@Audio3 for ambience texture.\nProduce a coherent 3-shot output (<=15s) with explicit transition verbs."
      }
    ],
    "tipsTitle": "Tips and boundaries",
    "strengths": [
      "Strong cinematic camera direction when beats are explicit.",
      "Improved continuity with multimodal references.",
      "Native audio sync in short multi-shot outputs.",
      "High utility for ads, action beats, and storyboard prototyping."
    ],
    "troubleshootingItems": [
      "Cuts feel abrupt -> add transition verbs and timestamps (match cut at 5s, whip pan into Shot 2).",
      "Continuity drifts -> add anchors (wardrobe, prop, location) and reuse references.",
      "Audio mismatch -> shorten dialogue, pin SFX to visible action, keep one ambience bed.",
      "Physics looks off -> simplify simultaneous actions per beat and reduce fast interactions."
    ],
    "boundaries": [
      "Pre-launch visibility does not imply runtime access.",
      "Launch-day endpoint exposure determines available advanced operations.",
      "Commercial details and pricing finalize at launch.",
      "Use only officially documented capabilities in production planning."
    ],
    "galleryTitle": "Seedance 2.0 examples",
    "galleryIntro": "Explore official references and prompt patterns while runtime remains locked pre-launch. We will publish real MaxVideoAI renders here once the model is live.",
    "galleryAllCta": "View all Seedance examples ->",
    "recreateLabel": "Recreate this shot ->",
    "demoTitle": "Demo prompt — Seedance 2.0",
    "demoPromptLabel": "Prompt"
  }
}
